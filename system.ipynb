{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05464fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display and Data Manipulation libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rd\n",
    "import os\n",
    "from IPython.display import display_html\n",
    "from itertools import chain, cycle\n",
    "\n",
    "# Data Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import bar\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from nltk.stem.porter import *\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "# Preprocessing Module libraries\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from collections import defaultdict\n",
    "from ast import literal_eval\n",
    "\n",
    "# Clustering Module libraries\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.cluster import KMeans \n",
    "\n",
    "# Classification Module libraries\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Evaluation Module libraries\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from sklearn.metrics import confusion_matrix, pairwise_distances\n",
    "from scipy import stats\n",
    "\n",
    "# Model Implementation libraries\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1ddf4c",
   "metadata": {},
   "source": [
    "# PRE-MODULES"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6064fc43",
   "metadata": {},
   "source": [
    "## METHODS & CONSTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a44fb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pandas display options\n",
    "def set_pandas_display_options() -> None:\n",
    "    display = pd.options.display\n",
    "    display.max_columns = 1000\n",
    "    display.max_rows = 1000\n",
    "    display.max_colwidth = 199\n",
    "    display.width = 1000\n",
    "set_pandas_display_options()\n",
    "\n",
    "# Display dataframes side by side\n",
    "def display_side_by_side(*args, titles=cycle([''])):\n",
    "    html_str= ''\n",
    "    for df, title in zip(args, chain(titles, cycle(['</br>'])) ):\n",
    "        html_str += '<th style=\"text-align:center\"><td style=\"vertical-align:top\">'\n",
    "        html_str += f'<h4 style=\"text-align: center;\">{title}</h4>'\n",
    "        html_str += df.to_html().replace('table','table style=\"display:inline\"')\n",
    "        html_str += '</td></th>'\n",
    "    display_html(html_str, raw=True)\n",
    "    \n",
    "# Convert list to list of lists\n",
    "def extract(lst):\n",
    "    return [[item] for item in lst]\n",
    "\n",
    "# Convert list of lists to list (similar to NumPy flatten())\n",
    "def flatten(lst):\n",
    "    return [item for sublist in lst for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2948ddee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classes and their colors\n",
    "classes = ['Negative', 'Neutral', 'Positive']\n",
    "targets = [-1.0, 0.0, 1.0]\n",
    "targets_str = ['-1.0', '0.0', '1.0']\n",
    "colors = ['Red', 'Blue', 'Green']\n",
    "\n",
    "# Define no. of clusters and classifiers, and metrics\n",
    "n_clusters = 6\n",
    "n_classifiers = 4\n",
    "clustering_metrics = ['Silhouette Coefficient', 'Calinski-Harabasz Index', 'Davies-Bouldin Index']\n",
    "classifier_metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "\n",
    "# File path\n",
    "PATH = 'datasets/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4152c40",
   "metadata": {},
   "source": [
    "## DATA INITIALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e5c771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read .CSV and show dataset\n",
    "df = pd.read_csv(os.path.join(PATH, 'covid19_tweets_dataset_translated.csv')).rename(\n",
    "    columns={'TWEETS': 'text_original', 'SENTIMENT': 'SENTIMENT SCORE', 'Translated_Tweets': 'text'})\n",
    "df = df.iloc[0:9160, 0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2710f13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the null values if there is any\n",
    "df = df.dropna()\n",
    "print(df.info())\n",
    "\n",
    "# Produce a copy of the dataset\n",
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479fd186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract tweets list from dataset\n",
    "hashtags = df2.text_original.str.extractall(r'(\\#\\w+)').reset_index(drop=True)\n",
    "hashtags_list = set(hashtags[0].str.lower().tolist()) # lower and remove duplicates\n",
    "hashtags_list = [entry[1:] for entry in hashtags_list] # remove hashtag symbol\n",
    "hashtags_list = [re.sub('[^A-Za-z0-9]+', '', entry) for entry in hashtags_list] # remove symbols\n",
    "hashtags_list = [entry for entry in hashtags_list if not entry.isdigit()] # remove digits\n",
    "hashtags_list = list(filter(None, hashtags_list)) # remove empty lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6731d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save hashtags list as .CSV\n",
    "np.savetxt(os.path.join(PATH, 'hashtags_list.csv'), hashtags_list, fmt='% s', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b01d023",
   "metadata": {},
   "source": [
    "## DATA VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb67fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Plot Visualization\n",
    "abs_values = df2['SENTIMENT SCORE'].value_counts()[targets]\n",
    "rel_values = df2['SENTIMENT SCORE'].value_counts(normalize=True)[targets].values * 100\n",
    "lbls = [f'{p[0]} ({p[1]:.0f}%)' for p in zip(abs_values, rel_values)]\n",
    "\n",
    "bx = sns.countplot(x=df2['SENTIMENT SCORE'], order=df2['SENTIMENT SCORE'].value_counts()[targets].index, palette=colors)\n",
    "bx.set_title('COVID19 TWEETS DATASET', fontsize=15)\n",
    "bx.bar_label(container=bx.containers[0], labels=lbls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee5bc1e",
   "metadata": {},
   "source": [
    "# I. PREPROCESSING MODULE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436b98a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove whitespace between @ and name\n",
    "def fix_mention(entry):\n",
    "    pattern = re.compile(r'@ ')\n",
    "    return re.sub(pattern, '@', entry)\n",
    "\n",
    "# Remove hyperlinks with whitespace in between\n",
    "def fix_hyperlink(entry):\n",
    "    pattern = re.compile(r'https?(\\s|)([!:])(\\s|)/(\\s|)(/|)(\\s|)\\S+(\\s|).(\\s|)\\S+(\\s|)(/|)(\\s|)\\S+')\n",
    "    return re.sub(pattern, '', entry)\n",
    "\n",
    "# Tagging words if it is noun, adjective, verb, or adverb\n",
    "def tagging_map():\n",
    "    tag_map = defaultdict(lambda: wn.NOUN)\n",
    "    tag_map['J'] = wn.ADJ\n",
    "    tag_map['V'] = wn.VERB\n",
    "    tag_map['R'] = wn.ADV\n",
    "    return tag_map\n",
    "\n",
    "# Save feature names or vocabulary\n",
    "def save_feature_names(feature_names):\n",
    "    np.savetxt(os.path.join(PATH, 'feature_names.csv'), feature_names, fmt='% s', encoding='utf-8')\n",
    "\n",
    "\n",
    "# Preprocess class\n",
    "class Preprocess:\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    # Change all the text to lower case\n",
    "    def lower(self):\n",
    "        self.dataframe['text_lower'] = [entry.lower() for entry in self.dataframe['text']]\n",
    "        return self.dataframe\n",
    "\n",
    "    # Remove whitespace between mentions and hyperlinks with whitespace in between\n",
    "    def cleaning_a(self):\n",
    "        self.dataframe['text_cleaned'] = [fix_mention(entry) for entry in self.dataframe['text_lower']]\n",
    "        self.dataframe['text_cleaned'] = [fix_hyperlink(entry) for entry in self.dataframe['text_cleaned']]\n",
    "        return self.dataframe\n",
    "\n",
    "    # Remove mentions, hyperlinks, and symbols\n",
    "    def cleaning_b(self):\n",
    "        self.dataframe['text_cleaned'] = [re.sub('@[A-Za-z0-9_]+', '', entry) for entry in\n",
    "                                        self.dataframe['text_cleaned']]\n",
    "        self.dataframe['text_cleaned'] = [re.sub('https?([!:])//\\\\S+', '', entry) for entry in\n",
    "                                        self.dataframe['text_cleaned']]\n",
    "        self.dataframe['text_cleaned'] = [re.sub('[^A-Za-z0-9_ ]+', '', entry) for entry in\n",
    "                                        self.dataframe['text_cleaned']]\n",
    "        return self.dataframe\n",
    "\n",
    "    # Tokenization process\n",
    "    def tokenization(self):\n",
    "        self.dataframe['text_tokenized'] = [word_tokenize(entry) for entry in self.dataframe['text_cleaned']]\n",
    "        return self.dataframe\n",
    "\n",
    "    # Lemmatization using WordNetLemmatizer()\n",
    "    def lemmatization(self, hashtags_list):\n",
    "        tag_map = tagging_map()\n",
    "        for index, entry in enumerate(self.dataframe['text_tokenized']):\n",
    "            lemmatized = []\n",
    "            word_lemmatized = WordNetLemmatizer()\n",
    "            for word, tag in pos_tag(entry):\n",
    "                # Removal of stop words and unnecessary text\n",
    "                if word not in stopwords.words('english') and (word.isalpha() or word in hashtags_list):\n",
    "                    # Lemmatization of each token is based on tag_map\n",
    "                    words = word_lemmatized.lemmatize(word, tag_map[tag[0]])\n",
    "                    lemmatized.append(words)\n",
    "                    # Processed set of words stored in 'text_lemmatized'\n",
    "            self.dataframe.loc[index, 'text_preprocessed'] = str(lemmatized)\n",
    "        return self.dataframe\n",
    "\n",
    "    def vectorization(self):\n",
    "        tfidf = TfidfVectorizer()\n",
    "        x = tfidf.fit_transform(self.dataframe['text_preprocessed'])\n",
    "        feature_names = tfidf.get_feature_names_out()\n",
    "        df_vectorized = pd.DataFrame(normalize(x).toarray(), columns=feature_names)\n",
    "        df_vectorized = pd.concat([df_vectorized, df2['SENTIMENT SCORE']], axis=1)\n",
    "        return df_vectorized, feature_names\n",
    "\n",
    "\n",
    "def preprocess(dataframe, hashtags_list):\n",
    "    df_process = Preprocess(dataframe)\n",
    "    df_process.lower()\n",
    "    df_process.cleaning_a()\n",
    "    df_process.cleaning_b()\n",
    "    df_process.tokenization()\n",
    "    return df_process.lemmatization(hashtags_list)\n",
    "\n",
    "def vectorize(dataframe):\n",
    "    df_vectorized, feature_names = Preprocess(dataframe).vectorization()\n",
    "    save_feature_names(feature_names)\n",
    "    return df_vectorized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3ec9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "df2 = preprocess(df2, hashtags_list)\n",
    "\n",
    "# Vectorization\n",
    "df_vectorized = vectorize(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bae577a",
   "metadata": {},
   "source": [
    "# II. CLUSTERING MODULE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011e7a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate X and y\n",
    "X = df_vectorized.drop(['SENTIMENT SCORE'], axis=1)\n",
    "y = df_vectorized['SENTIMENT SCORE']\n",
    "\n",
    "# Show distribution of instances per cluster\n",
    "def ModKMeansResults(labels):\n",
    "    counts = pd.DataFrame(labels).value_counts()\n",
    "    print(counts)\n",
    "    print(f'Total number of instances = {sum(counts.tolist())}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a1d7140",
   "metadata": {},
   "source": [
    "## MODIFIED K-MEANS CLUSTERING\n",
    "1. PCA & PERCENTILE METHOD\n",
    "2. WEIGHTED AVERAGE METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d404b4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Percentile List\n",
    "def PercentileList(ptiles, dataframe, n_clusters):\n",
    "    percentile_list = []\n",
    "    for x in range(1, n_clusters+1):\n",
    "        percentile = np.percentile(a=dataframe[0], q=ptiles*x, interpolation='linear')\n",
    "        percentile_list.append(percentile)\n",
    "    return percentile_list\n",
    "\n",
    "\n",
    "# Cluster class\n",
    "class Cluster:\n",
    "    def __init__(self, X, n_clusters):\n",
    "        self.X = X\n",
    "        self.n_clusters = n_clusters\n",
    "\n",
    "    # Principal Component Analysis (PCA) Method\n",
    "    def PCAMethod(self, pca_random_state):\n",
    "        pca = PCA(n_components=2, random_state=pca_random_state)\n",
    "        return pd.DataFrame(pca.fit_transform(self.X))\n",
    "\n",
    "    # Percentile Method\n",
    "    def PercentileMethod(self, dataframe):\n",
    "        ptiles = 1/self.n_clusters*100\n",
    "        percentile_list = PercentileList(ptiles, dataframe, self.n_clusters)\n",
    "        clusters = [list() for x in range(self.n_clusters)]\n",
    "            \n",
    "        for index, entry in enumerate(dataframe[0]):\n",
    "            if entry <= percentile_list[0]:\n",
    "                clusters[0].append(dataframe.iloc[index].tolist())        \n",
    "            elif entry <= percentile_list[1]:\n",
    "                clusters[1].append(dataframe.iloc[index].tolist())\n",
    "            elif entry <= percentile_list[2]:\n",
    "                clusters[2].append(dataframe.iloc[index].tolist())\n",
    "            elif entry <= percentile_list[3]:\n",
    "                clusters[3].append(dataframe.iloc[index].tolist())\n",
    "            elif entry <= percentile_list[4]:\n",
    "                clusters[4].append(dataframe.iloc[index].tolist())\n",
    "            elif entry <= percentile_list[5]:\n",
    "                clusters[5].append(dataframe.iloc[index].tolist())\n",
    "        return [pd.DataFrame(clusters[x]) for x in range(self.n_clusters)]\n",
    "\n",
    "    # Weighted Average Method\n",
    "    def WeightedAverage(self):\n",
    "        return np.array(np.true_divide(self.X.sum(1), (self.X != 0).sum(1)))\n",
    "\n",
    "    # Define Initial Centroids (PCA & Percentile)\n",
    "    def InitialCentroidsPP(self, df_clusters): \n",
    "        return [[df_clusters[x][y].mean() for y in range(len(df_clusters[x].columns))] for x in range(self.n_clusters)]\n",
    "\n",
    "    # Define Initial Centroids (Weighted Average)\n",
    "    def InitialCentroidsWA(self, row_means):\n",
    "        sorted_means_index = np.argsort(row_means, kind='mergesort', axis=0)\n",
    "        sorted_means = row_means[sorted_means_index]\n",
    "        groups = np.array_split(sorted_means, self.n_clusters)\n",
    "        group_mean = []\n",
    "        initial_centroids = []\n",
    "\n",
    "        for index, group in enumerate(groups):\n",
    "            g_mean = sum(group)/len(group)\n",
    "            g_mean = np.array([g_mean])\n",
    "            group_mean.append(g_mean)\n",
    "            group = np.array(pd.DataFrame(group).iloc[:, 0]).reshape(-1, 1)\n",
    "            \n",
    "            if g_mean.ndim == 1:\n",
    "                g_mean = g_mean.reshape(-1, 1)\n",
    "\n",
    "            dist_to_centroid = pairwise_distances(group, g_mean, metric='euclidean')\n",
    "            initial_centroid = np.argmin(dist_to_centroid)\n",
    "            initial_centroids.append(initial_centroid)\n",
    "        \n",
    "        centroids = row_means[initial_centroids]\n",
    "        return centroids\n",
    "    \n",
    "\n",
    "# Modified K-Means (PCA & Percentile)\n",
    "def ModKMeansPP(X, n_clusters, pca_random_state):\n",
    "    # PCA & Percentile Method, Define Initial Centroids\n",
    "    dataframe = Cluster(X, n_clusters)\n",
    "    df_pca = dataframe.PCAMethod(pca_random_state)\n",
    "    df_clusters = dataframe.PercentileMethod(df_pca)\n",
    "    modkmeans_centers = dataframe.InitialCentroidsPP(df_clusters)\n",
    "    \n",
    "    # K-Means Clustering Process with Proposed Initial Centroids\n",
    "    modkmeans = KMeans(n_clusters=n_clusters, init=modkmeans_centers, \n",
    "                               random_state=None, n_init=1, max_iter=1500)\n",
    "    return modkmeans, df_pca\n",
    "\n",
    "# Modified K-Means (Weighted Average)\n",
    "def ModKMeansWA(X, n_clusters):\n",
    "    # Define Initial Centroids through Weighted Average Method\n",
    "    dataframe = Cluster(X, n_clusters)\n",
    "    row_means = dataframe.WeightedAverage()\n",
    "    centroids = extract(dataframe.InitialCentroidsWA(row_means))\n",
    "    \n",
    "    # K-Means Clustering Process with Proposed Initial Centroids\n",
    "    modkmeans = KMeans(n_clusters=n_clusters, init=centroids, n_init=1, max_iter=1500)\n",
    "    means = row_means.reshape(-1, 1)\n",
    "    return modkmeans, means"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c7735b7",
   "metadata": {},
   "source": [
    "## MODIFIED K-MEANS CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e509d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified K-Means Clustering Implementation (PCA & Percentile)\n",
    "modkmeans_pp, dataframe = ModKMeansPP(X, n_clusters=6, pca_random_state=42)\n",
    "modkmeans = modkmeans_pp.fit(dataframe)\n",
    "print('Modified K-Means Clustering (PCA & Percentile)')\n",
    "ModKMeansResults(modkmeans.labels_)\n",
    "\n",
    "# Modified K-Means Clustering Implementation (Weighted Average)\n",
    "modkmeans_wa, means = ModKMeansWA(df_vectorized.drop(['SENTIMENT SCORE'], axis=1), n_clusters=6)\n",
    "modkmeans2 = modkmeans_wa.fit(means)\n",
    "print('\\nModified K-Means Clustering (Weighted Average)')\n",
    "ModKMeansResults(modkmeans2.labels_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2fe47b9b",
   "metadata": {},
   "source": [
    "## CLUSTER DIVIDING & LABELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107cac4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cluster number to each instance in the Tweets Dataset\n",
    "def Labels(df_vectorized, modkmeans_labels):\n",
    "    df_vectorized['CLUSTER NUMBER'] = modkmeans_labels\n",
    "    return df_vectorized\n",
    "\n",
    "\n",
    "# ClusterDivide class\n",
    "class ClusterDivide:\n",
    "    def __init__(self, cluster_X, cluster_y, n_clusters):\n",
    "        self.cluster_X = cluster_X\n",
    "        self.cluster_y = cluster_y\n",
    "        self.n_clusters = n_clusters\n",
    "    \n",
    "    # Divide the Tweets Dataset based on clusters\n",
    "    def DivideCluster(self, df_vectorized):\n",
    "        for x in range(self.n_clusters):\n",
    "            self.cluster_X[x] = df_vectorized[df_vectorized['CLUSTER NUMBER'] == x]\n",
    "        for x in range(self.n_clusters):\n",
    "            self.cluster_y[x] = pd.Series(self.cluster_X[x]['SENTIMENT SCORE'], dtype='int32')\n",
    "        return self.cluster_X, self.cluster_y, df_vectorized\n",
    "\n",
    "    # Drop the 'CLUSTER NUMBER' and 'SENTIMENT SCORE' columns\n",
    "    def DropColumn(self, df_vectorized):\n",
    "        for x in range(self.n_clusters):\n",
    "            self.cluster_X[x] = self.cluster_X[x].drop(['CLUSTER NUMBER', 'SENTIMENT SCORE'], axis=1)\n",
    "        df_vectorized = df_vectorized.drop(['CLUSTER NUMBER'], axis=1)   \n",
    "        return self.cluster_X, df_vectorized\n",
    "\n",
    "    # Display the clusters\n",
    "    def DisplayCluster(self):\n",
    "        for x in range(self.n_clusters):\n",
    "            print('Cluster', str(x), '->', len(self.cluster_X[x]))\n",
    "\n",
    "\n",
    "class ClusterLabel:\n",
    "    def __init__(self, series, text):\n",
    "        self.series = series\n",
    "        self.text = text\n",
    "    \n",
    "    # Detokenizer before using CountVectorizer\n",
    "    def detokenization(self):\n",
    "        detokenizer = TreebankWordDetokenizer()\n",
    "\n",
    "        for item in self.series:\n",
    "            word = detokenizer.detokenize(literal_eval(item))\n",
    "            self.text.append(word)\n",
    "        return self.text\n",
    "\n",
    "    # Dataframe with TEXT, SENTIMENT SCORE, and CLUSTER NUMBER\n",
    "    def create_dataframe(self, sentiment_score, modkmeans_labels):\n",
    "        dataframe = pd.DataFrame(self.text).rename(columns={0: 'TEXT'})\n",
    "        dataframe['SENTIMENT SCORE'] = sentiment_score\n",
    "        dataframe['CLUSTER NUMBER'] = modkmeans_labels\n",
    "        return dataframe\n",
    "\n",
    "\n",
    "# Cluster Dividing\n",
    "def cluster_dividing(df_vectorized, modkmeans_labels):\n",
    "    # Create empty lists\n",
    "    cluster_X = [list() for x in range(n_clusters)]\n",
    "    cluster_y = [list() for x in range(n_clusters)]\n",
    "    \n",
    "    # Process\n",
    "    df_vectorized = Labels(df_vectorized, modkmeans_labels)\n",
    "    cluster_divide = ClusterDivide(cluster_X, cluster_y, n_clusters)\n",
    "    cluster_X, cluster_y, df_vectorized = cluster_divide.DivideCluster(df_vectorized)\n",
    "    cluster_X, df_vectorized = cluster_divide.DropColumn(df_vectorized)\n",
    "    return cluster_X, cluster_y, df_vectorized\n",
    "\n",
    "# Cluster Labeling using CountVectorizer\n",
    "def cluster_labeling(n_clusters, top_words, sentiment_score, modkmeans_labels):\n",
    "    # Initialize\n",
    "    cv = CountVectorizer()\n",
    "    cv_clusters = [pd.DataFrame() for x in range(n_clusters)]\n",
    "    \n",
    "    # Create dataframe for Cluster Labeling\n",
    "    cluster_label = ClusterLabel(df2['text_preprocessed'], list())\n",
    "    cluster_label.detokenization()\n",
    "    dataframe = cluster_label.create_dataframe(sentiment_score, modkmeans_labels)\n",
    "\n",
    "    # Get the frequency of each token from the text\n",
    "    for x in range(n_clusters):\n",
    "        matrix = cv.fit_transform(dataframe['TEXT'][dataframe['CLUSTER NUMBER'] == x])\n",
    "        counts = pd.DataFrame(matrix.toarray(), columns = cv.get_feature_names_out())\n",
    "        counts.loc['Total', :] = counts.sum(axis=0)\n",
    "\n",
    "        # Create the DataFrame\n",
    "        freq = counts.iloc[len(counts)-1]\n",
    "        cv_clusters[x] = pd.DataFrame(freq, dtype='int').sort_values(by = ['Total'], ascending = False)\n",
    "        cv_clusters[x]['%'] = cv_clusters[x]['Total'].astype(float).transform(lambda x: x / x.sum() * 100).round(2)\n",
    "        cv_clusters[x] = cv_clusters[x].reset_index().rename(columns = {'index': 'Hashtag'}).iloc[0:top_words]\n",
    "    return dataframe, cv_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8456a0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide and label clusters\n",
    "cluster_X, cluster_y, df_vectorized = cluster_dividing(df_vectorized, modkmeans.labels_)\n",
    "df_labelled, cv_clusters = cluster_labeling(n_clusters=n_clusters, top_words=5, \n",
    "    sentiment_score=df2['SENTIMENT SCORE'], modkmeans_labels=modkmeans.labels_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4562e4e0",
   "metadata": {},
   "source": [
    "## CLUSTER VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fc03c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar Plot Visualization on Hashtags per cluster\n",
    "title_clusters = ['CLUSTER ' + str(x) for x in range(n_clusters)]\n",
    "for x in range(n_clusters):\n",
    "    ax = sns.barplot(data=cv_clusters[x], x='Total', y='Hashtag', orient='h')\n",
    "    ax.set_title(title_clusters[x])\n",
    "    ax.bar_label(ax.containers[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2396e420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Plot Visualization on Sentiment Score per cluster\n",
    "ax = [0, 1, 2, 3, 4, 5]\n",
    "fig, ((ax[0], ax[1], ax[2]), (ax[3], ax[4], ax[5])) = plt.subplots(nrows=2, ncols=3, figsize=(15, 10))\n",
    "\n",
    "for x in range(n_clusters):  \n",
    "    try:\n",
    "        ax[x] = sns.countplot(x=cluster_y[x], ax=ax[x], order=cluster_y[x].value_counts()[targets].index, palette=colors)\n",
    "        abs_values = cluster_y[x].value_counts()[targets]\n",
    "        rel_values = cluster_y[x].value_counts(normalize=True)[targets].values * 100\n",
    "    except:\n",
    "        ax[x] = sns.countplot(x=cluster_y[x], ax=ax[x], palette=colors)\n",
    "        abs_values = cluster_y[x].value_counts()\n",
    "        rel_values = cluster_y[x].value_counts(normalize=True).values * 100\n",
    "    lbls = [f'{p[0]} ({p[1]:.0f}%)' for p in zip(abs_values, rel_values)]\n",
    "    ax[x].set_title('CLUSTER ' + str(x), fontsize=15)\n",
    "    ax[x].bar_label(container=ax[x].containers[0], labels=lbls)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "195065b1",
   "metadata": {},
   "source": [
    "## CLUSTER LABELS\n",
    "Cluster 0: Government Response<br>\n",
    "Cluster 1: General Updates<br>\n",
    "Cluster 2: News Updates<br>\n",
    "Cluster 3: Case Projections and Predictions<br>\n",
    "Cluster 4: COVID-19 Updates<br>\n",
    "Cluster 5: COVID-19 Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6603c7",
   "metadata": {},
   "source": [
    "# III. CLASSIFICATION MODULE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45562f8b",
   "metadata": {},
   "source": [
    "## CLASSIFICATION METHODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cd4694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for Base Estimators classification process\n",
    "def BaseEstimators(classifiers, n_clusters, cluster_X, cluster_Y, results, random_state, dump):\n",
    "    # Prepare lists\n",
    "    Test_X_BE = list()\n",
    "    Test_Y_BE = list()\n",
    "    predictions = list()\n",
    "    scores = list()\n",
    "    ps_list = list()\n",
    "    rs_list = list()\n",
    "    fs_list = list()\n",
    "    \n",
    "    for x in range(n_clusters):\n",
    "        # Prepare Train and Test Data sets\n",
    "        Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(cluster_X[x], cluster_Y[x],\n",
    "                test_size=0.3, random_state=random_state)\n",
    "        Test_X_BE.append(Test_X)\n",
    "        Test_Y_BE.append(Test_Y)\n",
    "\n",
    "        # Process\n",
    "        for name, model in classifiers:\n",
    "            model.fit(Train_X, Train_Y)\n",
    "            predict = model.predict(Test_X)\n",
    "            accuracy = accuracy_score(predict, Test_Y)*100\n",
    "            predictions.append(predict)\n",
    "            scores.append(accuracy)\n",
    "            \n",
    "            if results == 'eval':\n",
    "                ps_list.append(precision_score(Test_Y, predict, labels=targets, zero_division=0, average='weighted')*100)\n",
    "                rs_list.append(recall_score(Test_Y, predict, labels=targets, zero_division=0, average='weighted')*100)\n",
    "                fs_list.append(f1_score(Test_Y, predict, labels=targets, zero_division=0, average='weighted')*100)\n",
    "            \n",
    "            if dump:\n",
    "                joblib.dump(model, 'models/' + name + '_Cluster' + str(x) + '.pkl')\n",
    "    \n",
    "    # return accuracy only\n",
    "    if results == 'acc':\n",
    "        return scores\n",
    "    # model evaluation\n",
    "    elif results == 'eval':\n",
    "        return scores, ps_list, rs_list, fs_list\n",
    "    # default; results == 'all'\n",
    "    else:\n",
    "        return Test_X_BE, Test_Y_BE, predictions, scores\n",
    "\n",
    "# Method to initialize ensemble model weights\n",
    "def EnsembleWeights(scores, n_clusters, n_classifiers, scaler):\n",
    "    iterations = [x for i in range(n_classifiers) for x in range(n_clusters*n_classifiers) if i == x % n_classifiers]\n",
    "    initial_weights = []\n",
    "    scaled_weights = []\n",
    "    \n",
    "    # Initial weights\n",
    "    for x in range(0, n_clusters*n_classifiers, n_classifiers):\n",
    "        initial_weights.append([y/sum(scores[x:x+n_classifiers]) for y in scores[x:x+n_classifiers]])\n",
    "    initial_weights = np.array(initial_weights).reshape(n_clusters, n_classifiers)\n",
    "    \n",
    "    # Scaled weights\n",
    "    for x in range(len(initial_weights)):\n",
    "        scaled_weights.append(scaler.fit_transform(initial_weights[x].reshape(-1, 1)))\n",
    "    scaled_weights = [flatten(scaled_weights[x]) for x in range(len(scaled_weights))] \n",
    "\n",
    "    # Show scaled weights \n",
    "    for x in range(n_clusters):\n",
    "        print('CLUSTER', str(x), 'scaled weights ->', scaled_weights[x])\n",
    "    return scaled_weights\n",
    "\n",
    "# Method for Ensemble Model process\n",
    "def EnsembleModel(models, scaled_weights, n_clusters, cluster_X, cluster_Y, results, random_state, dump):\n",
    "    # Prepare lists\n",
    "    Test_X_ENS = list()\n",
    "    Test_Y_ENS = list()\n",
    "    predictions_ENS = list()\n",
    "    scores_ENS = list()\n",
    "    ps_list = list()\n",
    "    rs_list = list()\n",
    "    fs_list = list()\n",
    "\n",
    "    for x in range(n_clusters):\n",
    "        # Prepare ensemble model with defined weights\n",
    "        ensembles = VotingClassifier(estimators=models, weights=scaled_weights[x], voting='hard')\n",
    "        \n",
    "        # Prepare Train and Test Data sets\n",
    "        Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(cluster_X[x], cluster_Y[x],\n",
    "                test_size=0.3, random_state=random_state)\n",
    "        Test_X_ENS.append(Test_X)\n",
    "        Test_Y_ENS.append(Test_Y)\n",
    "\n",
    "        # Fit and evaluate the ensemble method\n",
    "        ensembles.fit(Train_X, Train_Y)\n",
    "        predict = ensembles.predict(Test_X)\n",
    "        accuracy = accuracy_score(predict, Test_Y)*100\n",
    "        predictions_ENS.append(predict)\n",
    "        scores_ENS.append(accuracy)\n",
    "        \n",
    "        if results == 'eval':\n",
    "            ps_list.append(precision_score(Test_Y, predict, labels=targets, zero_division=0, average='weighted')*100)\n",
    "            rs_list.append(recall_score(Test_Y, predict, labels=targets, zero_division=0, average='weighted')*100)\n",
    "            fs_list.append(f1_score(Test_Y, predict, labels=targets, zero_division=0, average='weighted')*100)\n",
    "        \n",
    "        if dump:\n",
    "            joblib.dump(ensembles, 'models/ENS_Cluster' + str(x) + '.pkl')\n",
    "    \n",
    "    # return accuracy only\n",
    "    if results == 'acc':\n",
    "        return scores_ENS\n",
    "    # model evaluation\n",
    "    elif results == 'eval':\n",
    "        return scores_ENS, ps_list, rs_list, fs_list\n",
    "    # default; results == 'all'\n",
    "    else:\n",
    "        return Test_X_ENS, Test_Y_ENS, predictions_ENS, scores_ENS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d14b0fbe",
   "metadata": {},
   "source": [
    "## BASE ESIMATORS TRAINED\n",
    "('CNB', ComplementNB())<br>\n",
    "('SVM', LinearSVC(random_state=42))<br>\n",
    "('LR', LogisticRegression(multi_class='multinomial', random_state=42, solver='saga'))<br>\n",
    "('RF', RandomForestClassifier(max_depth=120, random_state=42))<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f83f014f",
   "metadata": {},
   "source": [
    "## BASE ESTIMATORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b90cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare classifier algorithms\n",
    "CNB = naive_bayes.ComplementNB()\n",
    "SVM = svm.LinearSVC(C=1.0, penalty='l2', dual=True, random_state=42, max_iter=1000)\n",
    "LR = LogisticRegression(C=1.0, penalty='l2', solver='saga', dual=False, \n",
    "        multi_class='multinomial', random_state=42, max_iter=100)\n",
    "RF = RandomForestClassifier(max_depth=120, random_state=42)\n",
    "\n",
    "classifiers = [('CNB', CNB), ('SVM', SVM), ('LR', LR), ('RF', RF)]\n",
    "actual_classifiers = [(items[0] + '_CLUSTER_' + str(int(index/n_classifiers))) for index, items in enumerate(classifiers*n_clusters)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124a786c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and evaluate the base estimators CNB, SVM, LR, & RF\n",
    "Test_X_BE, Test_Y_BE, predictions, scores = BaseEstimators(classifiers, n_clusters, cluster_X, cluster_y,\n",
    "        results='all', random_state=42, dump=False)\n",
    "\n",
    "# Accuracies\n",
    "for x in range(len(actual_classifiers)):\n",
    "    print(actual_classifiers[x] + '_accuracy -> %.4f' % scores[x])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1b9d726e",
   "metadata": {},
   "source": [
    "## COMBINATION ENSEMBLE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57756e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare ensemble model weights, lists, and seed\n",
    "scaler = MinMaxScaler()\n",
    "scaled_weights = EnsembleWeights(scores, n_clusters, n_classifiers, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc77725f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and evaluate the Ensemble Model\n",
    "Test_X_ENS, Test_Y_ENS, predictions_ENS, scores_ENS = EnsembleModel(classifiers, scaled_weights, n_clusters, cluster_X, cluster_y,\n",
    "        results='all', random_state=42, dump=False)\n",
    "\n",
    "# Accuracy\n",
    "for x in range(n_clusters):\n",
    "    print('ENS_CLUSTER_' + str(x) + '_accuracy -> %.4f' % scores_ENS[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3deac8",
   "metadata": {},
   "source": [
    "# IV. EVALUATION MODULE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc980561",
   "metadata": {},
   "source": [
    "## CLUSTERING MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bd308d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA Method for Visualization\n",
    "df_pca = Cluster(X, n_clusters).PCAMethod(pca_random_state=42)\n",
    "df_pca['SENTIMENT SCORE'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6630ba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plot of Modified K-Means\n",
    "plt.scatter(x=df_pca[0], y=df_pca[1], c=modkmeans.labels_)\n",
    "plt.scatter(x=modkmeans.cluster_centers_.T[0], y=modkmeans.cluster_centers_.T[1], c='Black', marker='x')\n",
    "plt.title('Tweets Dataset Modified K-Means Clustering (PCA & Percentile)', fontsize=12)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a163b9b",
   "metadata": {},
   "source": [
    "### SUMMARY OF METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9e4cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified K-Means (PCA and Percentile) Silhouette Score, Calinski-Harabasz Index, and Davies-Bouldin Index\n",
    "print('Modified K-Means (PCA and Percentile) Metrics')\n",
    "print('Silhouette Score =', silhouette_score(df_pca[[0, 1]], labels=modkmeans.labels_))\n",
    "print('Calinski-Harabasz Index =', calinski_harabasz_score(df_pca[[0, 1]], labels=modkmeans.labels_))\n",
    "print('Davies-Bouldin Index =', davies_bouldin_score(df_pca[[0, 1]], labels=modkmeans.labels_))\n",
    "\n",
    "# Modified K-Means (Weighted Average) Silhouette Score, Calinski-Harabasz Index, and Davies-Bouldin Index\n",
    "print('\\nModified K-Means (Weighted Average) Metrics')\n",
    "print('Silhouette Score =', silhouette_score(means, labels=modkmeans2.labels_))\n",
    "print('Calinski-Harabasz Index =', calinski_harabasz_score(means, labels=modkmeans2.labels_))\n",
    "print('Davies-Bouldin Index =', davies_bouldin_score(means, labels=modkmeans2.labels_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efcb46c",
   "metadata": {},
   "source": [
    "## CLASSIFIER MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7b8c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction data for each base estimator\n",
    "predictions_BE = [predictions[x] for i in range(n_classifiers) for x in range(n_clusters*n_classifiers) if i == x % n_classifiers] + predictions_ENS\n",
    "predictions_NAMES = [classifiers[x][0] for x in range(n_classifiers)]\n",
    "predictions_NAMES.append('ENS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172f193c",
   "metadata": {},
   "source": [
    "### CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2012bfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_array(conf_matrix, Test_Y, predictions, n_clusters, classifier_n):\n",
    "    for x in range(n_clusters):\n",
    "        conf_matrix[x] = confusion_matrix(np.array(Test_Y_BE[x]), predictions_BE[x+n_clusters*classifier_n])   \n",
    "    return conf_matrix\n",
    "\n",
    "def confusion_matrix_heatmap(conf_matrix, c_algo):  \n",
    "    cx = [0, 1, 2, 3, 4, 5]\n",
    "    fig, ((cx[0], cx[1], cx[2]), (cx[3], cx[4], cx[5])) = plt.subplots(nrows=2, ncols=3, figsize=(14, 8.5), layout='tight', dpi=80)\n",
    "\n",
    "    for x in range(n_clusters):\n",
    "        cx[x] = sns.heatmap(conf_matrix[x], annot=True, fmt='d', ax=cx[x])\n",
    "        cx[x].xaxis.set_ticklabels(targets_str)\n",
    "        cx[x].yaxis.set_ticklabels(targets_str)\n",
    "        cx[x].set(xlabel='Predicted label', ylabel='True label')\n",
    "        cx[x].set_title('Matrix_' + c_algo + '_CLUSTER_' + str(x), fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb85cf47",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Classifier Algorithms Confusion Matrix\n",
    "conf_matrix = [[]] * n_clusters\n",
    "\n",
    "# Confusion Matrix\n",
    "for x in range(n_classifiers+1):\n",
    "    conf_matrix = confusion_matrix_array(conf_matrix, Test_Y_BE, predictions_BE, n_clusters, x)\n",
    "    confusion_matrix_heatmap(conf_matrix=conf_matrix, c_algo=predictions_NAMES[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8a716b",
   "metadata": {},
   "source": [
    "# POST-MODULES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa30a78d",
   "metadata": {},
   "source": [
    "## MODEL IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664a211d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input entry/entries of strings\n",
    "user_input = input('Input your sentiment: ')\n",
    "user_input = pd.DataFrame([user_input], columns={'text'})\n",
    "display(user_input)\n",
    "\n",
    "# Get hashtags list\n",
    "hashtags_testing = pd.read_csv('datasets/hashtags_list.csv', sep=',', header=None)\n",
    "hashtags_list_testing = flatten(hashtags_testing.values)\n",
    "\n",
    "# Preprocess entry\n",
    "process_input = Preprocess(user_input)\n",
    "process_input.lower()\n",
    "process_input.cleaning_a()\n",
    "process_input.cleaning_b()\n",
    "process_input.tokenization()\n",
    "data_frame = process_input.lemmatization(hashtags_list_testing)\n",
    "\n",
    "# Read vocabulary\n",
    "df_vocabulary = pd.read_csv('datasets/feature_names.csv', sep=',', header=None)\n",
    "vocabulary = flatten(df_vocabulary.values)\n",
    "\n",
    "# Check if vocabulary is empty\n",
    "if data_frame['text_preprocessed'][0] == '[]':\n",
    "    print('Empty vocabulary, your input likely only contain stop words.')\n",
    "else:\n",
    "    # Tfidf Vectorizer\n",
    "    tfidf_testing = TfidfVectorizer(vocabulary=vocabulary)\n",
    "    x_testing = tfidf_testing.fit_transform(data_frame['text_preprocessed'])\n",
    "\n",
    "    # Normalize data\n",
    "    df = pd.DataFrame(normalize(x_testing).toarray(), columns=tfidf_testing.get_feature_names_out())\n",
    "\n",
    "    if (df.T[0] == 0.0).all():\n",
    "        print('Invalid input or your sentiment contains unrecognized text.')\n",
    "\n",
    "    else:\n",
    "        # Load ensemble model\n",
    "        for x in range(n_clusters):\n",
    "            ensemble_testing = joblib.load('models/ENS_Cluster' + str(x) +'.pkl')\n",
    "\n",
    "            # Predict sample\n",
    "            print(f'ENS Cluster {str(x)} predicted {ensemble_testing.predict(df)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
